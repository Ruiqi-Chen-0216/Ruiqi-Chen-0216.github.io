---
permalink: /
title: ""
excerpt: ""
author_profile: true
layout: default
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Ruiqi Chen, I am currently pursuing a Master of Science in  [Human Centered Design & Engineering](https://www.hcde.washington.edu/) at the **University of Washington**, affiliated with [Makeability Lab](https://makeabilitylab.cs.washington.edu/) by [Prof. Jon E. Froehlich](https://jonfroehlich.github.io/) and [ACE Lab](https://depts.washington.edu/acelab/index.html) by [Prof. Jacob O. Wobbrock](https://faculty.washington.edu/wobbrock/). Previously, I received my Dual Bachelor's degree in Data Science from **Duke University** and **Duke Kunshan University** in May 2024, and was an undergraduate researcher scientist in [DKU HCI Lab](https://arkxlab.github.io/) advised by [Prof. Xin Tong](https://scholar.google.ca/citations?user=XIM08ZwAAAAJ&hl=en).

My research interests lie primarily at the intersection of Human-Computer Interaction(HCI) and Artificial Intelligence(AI), combining human and machine intelligence to create interactive systems for creativity, collaboration, and beyond. In my past three years of research experience, my research scope has included Human-Centered AI, Human-AI Collaboration, Computer Vision, Machine Learning, and Extended Reality.

**<span style="font-size: 24px;">I am enthusiastically pursuing a PhD position in CS starting from 2026 fall!</span>**



# üî• News
- *2025.02*: &nbsp;üéâüéâ Two of my undergraduate research works are accepted by CHI 2025!

- *2024.09*: &nbsp;üéâüéâ I joined the ACE Lab directed by Prof. Jacob O. Wobbrock at University of Washington, focusing on AI for accessibility and creative task!

- *2024.05*: &nbsp;üéâüéâ I joined the Makeability Lab directed by Prof. Jon E. Froehlich at University of Washington, and began my research journey at University of Washington! 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2025</div><img src='images/NSZT.png' alt="sym" width="80%"></div></div>
<div class='paper-box-text' markdown="1">

### Immersive Biography: Supporting Intercultural Empathy and Understanding for Displaced Cultural Objects in Virtual Reality

Ke Zhao, **Ruiqi Chen**, Xiaziyu Zhang, Chenxi Wang, Siling Chen, Xiaoguang Wang, Yujue Wang, Xin Tong

*ACM CHI Conference on Human Factors in Computing Systems* (**CHI2025**)

[Paper](https://dl.acm.org/doi/10.1145/3706598.3714303)

<!-- - This paper presents an immersive VR biography of the Admonitions Scroll to explore how embodied interactions with displaced cultural objects can promote intercultural empathy. Our findings showed that such interactions enhance understanding and interest in cultural heritage, offering a novel approach to representing and interpreting historical artifacts. -->
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">UIST 2024</div><img src='images/DIAM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DIAM: Drone-based Indoor Accessibility Mapping](https://makeabilitylab.cs.washington.edu/project/diam/)

Xia Su, **Ruiqi Chen**, Weiye Zhang, Jingwei Ma, Jon E. Froehlich

[**Project**](https://dl.acm.org/doi/10.1145/3672539.3686782) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This paper introduces Drone-based Indoor Accessibility Mapping (DIAM), a drone-based indoor scanning system that efficiently produces 3D reconstructions of indoor spaces with key accessibility facilities recognized and located in the model. With DIAM, users can scan indoor spaces quickly and generate a precise, detailed, and visual 3D indoor accessibility map.
</div>
</div>


<!-- - [**WACV 2025**] What's Happening" - A Human-centered Multimodal Interpreter Explaining the Actions of Autonomous Vehicles, (camera-ready version coming soon) -->

<!-- - [**CHI 2025**] GestoBrush: Enhancing Graffiti Artists‚Äô Digital Creation Experience with Embodied AR Interactions, **Ruiqi Chen**, Qingyang He, Hanxi Bao, Jung E. Choi, Xin Tong -->

- [**CHI 2025**] [Parental Perceptions of Children's d/Deaf Identity Shaping Technology Use: A Qualitative Study on Communication Technologies in Mixed-hearing Families](https://doi.org/10.1145/3706599.3719753), Keyi Zeng, Jingyang Lin, **Ruiqi Chen**, RAY LC, Pan Hui, Xin Tong

- [**IEEE VR 2023**] [Design and Evaluation of a VR Therapy for Patients with Mild Cognitive Impairment and Dementia: Perspectives from Patients and Stakeholders](https://ieeexplore.ieee.org/document/10108617/), **Ruiqi Chen**, Shuhe Wang, Xuhai Xu, Lan Wei, Yuling Sun, Xin Tong

- [**ChineseCHI 2023**] [Exploring Designers' Perceptions and Practices of Collaborating with Generative AI as a Co-creative Agent in a Multi-stakeholder Design Process: Take the Domain of Avatar Design as an Example](https://dl.acm.org/doi/fullHtml/10.1145/3629606.3629675), Qingyang He, Weicheng Zheng, Hanxi Bao, **Ruiqi Chen**, Xin Tong





**About Manuscripts**: 

There are 3 projects currently ongoing:
1. DocLLM: Agentic Query and Human-Aligned Evaluation for Complex Document-LLM Understanding
2. A11yBLV: Making GAI Creativity Accessible to Blind and Low-Vision Users (advised by Prof. Jacob O. Wobbrock)
3. RISSHAI: Room Intelligence and Safety Scanning with Human-AI Collaboration System (advised by Jon E. Froehlich)

and 5 projects are under submission & review: 
1. FlyOnlyOnce: 3D Drone-based Indoor AI Mapping System with Only Once Flying (In Submission)
2. CreA11y: A Dataset for Evaluating GAI Creativity with LLMs for Blind and Low-Vision Users (In Submission)
3. Enhancing Memory and Communication Abilities in Mild Dementia: A Personalized Memory Collage App with AIGC Technology (In Submission)
4. CreationBlends Reality: Enhancing Users' Socio-spatial Perceptions through Embodied Gestural Interactions in a Co-creative AR Environment (In Submission)
5. Revitalizing Public Spaces with Augmented Reality Art at Common Space (Under Review)



# üéñ Teaching, Mentorship and Service
* Paper reviewer for ACM Conference on Human Factors in Computing Systems (CHI), 2025
<!--# üéñ Honors and Awards-->
<!--- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->
<!--- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->

# üìñ Educations
* M.S. in Human Centered Design & Engineering, University of Washington, 2024 - 2026
* B.S. in Interdisciplinary Studies of Data Science, Duke University, 2020 - 2024
* B.S. in Data Science, Duke Kunshan University, 2020 - 2024

# üìö Experiences

<!-- 
* [EPIC Data Lab](https://epic.berkeley.edu/), University of California, Berkeley
  * Graduate Research Assistant to [Prof. Aditya Parameswaran](https://people.eecs.berkeley.edu/~adityagp/) 
  * Date: April 2025 ‚Äì Present
  * Contribute to two research project, focusing on LLM system and semantic data processing in HAI.
  -->

* [ACE Lab](https://depts.washington.edu/acelab/index.html), University of Washington
  * Graduate Research Assistant to [Prof. Jacob O. Wobbrock](https://faculty.washington.edu/wobbrock/) 
  * Date: September 2024 ‚Äì Present
  * Contribute to two research project, focusing on HAI creativity and interaction.

* [Makeability Lab](https://makeabilitylab.cs.washington.edu/), University of Washington
  * Graduate Research Assistant to [Prof. Jon E. Froehlich](https://jonfroehlich.github.io/) 
  * Date: May 2024 ‚Äì Present
  * Contribute to two research project, focusing on HAI system, CV and 3DV.

* [AI & Art for Knowledge & Creativity (ARK) Lab](https://arkxlab.github.io/), Hong Kong University of Science and Technology (GZ)
  * Graduate Research Assistant to [Prof. Xin Tong](https://cma.hkust-gz.edu.cn/people/tong-xin/)    
  * Date: June 2024 ‚Äì September 2024
  * Contribute to one research project, focusing on HCI and accessibility.

* [Human-Computer Interaction (HCI) Lab](https://arkxlab.github.io/), Duke Kunshan University
  * Undergraduate Research Assistant to [Prof. Xin Tong](https://scholar.google.com/citations?user=XIM08ZwAAAAJ&hl=zh-CN&oi=sra)    
  * Date: March 2022 ‚Äì June 2024
  * Contribute to five research projects, focusing on HCI, AI, and VR.

* Anthropocene Extended Reality (XR) Lab, Duke Kunshan University
  * Undergraduate Research Assistant to [Prof. Jung Choi](https://jungchoi.org/) and [Prof. Xin Tong](https://scholar.google.com/citations?user=XIM08ZwAAAAJ&hl=zh-CN&oi=sra)   
  * Date: May 2022 ‚Äì May 2024
  * Contribute to two research projects, focusing on HCI, AR and MR. 
  

<!-- # üíª Internships
- *2023.07 - 2023.08*, Artificial Intelligence Engineer Intern, Nanjing Institute of Mathware Technology, China.
- *2021.06 - 2021.08*, Software Engineering Process Group Intern, China Unicom Smart Connection Technology, China. -->

# üìß Contact Me
- If you have a research project related to Human-AI, especially on GAI & HAI creativity, and are looking for a collaborator proficient in AI algorithms, please feel free to contact me!